{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "Y = iris.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plus Proche Voisin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "\n",
    "def PPV(X,Y):\n",
    "    loo = LeaveOneOut()\n",
    "    res = []\n",
    "    \n",
    "    for train_index, test_index in loo.split(X):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = Y[train_index], Y[test_index]\n",
    "        \n",
    "        res.append((y_train[np.argmin(euclidean_distances(X_train,X_test).flatten())]))\n",
    "        \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2\n",
    "def PPV(X,Y):\n",
    "    loo = LeaveOneOut()\n",
    "    res = []\n",
    "    \n",
    "    for train_index, test_index in loo.split(X):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = Y[train_index], Y[test_index]\n",
    "        \n",
    "        res.append((y_train[np.argmin(euclidean_distances(X_train,X_test).flatten())]))\n",
    "        erreur = len([i for i in range(len(res)) if res[i] != Y[i]])/len(res)\n",
    "        \n",
    "    return res,erreur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n",
      "Erreur:  4.0 %\n"
     ]
    }
   ],
   "source": [
    "# 3\n",
    "y_pred,erreur = PPV(X,Y)\n",
    "print(y_pred)\n",
    "print(\"Erreur: \",erreur*100,\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erreur: 4.0 %\n",
      "Remarque: Les résultats sont égaux pour K=1\n",
      "Erreur pour k = 2 est: 5.333333333333334 %\n",
      "Erreur pour k = 3 est: 4.0 %\n",
      "Erreur pour k = 4 est: 4.0 %\n",
      "Erreur pour k = 5 est: 3.3333333333333335 %\n",
      "Erreur pour k = 6 est: 4.0 %\n",
      "Erreur pour k = 7 est: 3.3333333333333335 %\n",
      "Erreur pour k = 8 est: 3.3333333333333335 %\n",
      "Erreur pour k = 9 est: 3.3333333333333335 %\n"
     ]
    }
   ],
   "source": [
    "# 4\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "def KNN(K):\n",
    "    knn = KNeighborsClassifier(n_neighbors=K, metric='euclidean')\n",
    "    loo = LeaveOneOut()\n",
    "    res = []\n",
    "\n",
    "    for train_index, test_index in loo.split(X):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = Y[train_index], Y[test_index]\n",
    "\n",
    "        knn.fit(X_train, y_train)\n",
    "        res.append(knn.predict(X_test)[0])\n",
    "\n",
    "    erreur = len([res[i] for i in range(0, len(res)) if res[i] != Y[i]])/len(res)\n",
    "    return erreur\n",
    "    \n",
    "    \n",
    "print(\"Erreur:\",KNN(1)*100,\"%\")\n",
    "print(\"Remarque: Les résultats sont égaux pour K=1\")\n",
    "\n",
    "# pour autres valeurs de K\n",
    "for i in range(2,10):\n",
    "    print(\"Erreur pour k =\",i,\"est:\",KNN(i)*100,\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erreur pour k = 2 est: 4.0 %\n",
      "Erreur pour k = 3 est: 4.0 %\n",
      "Erreur pour k = 4 est: 4.0 %\n",
      "Erreur pour k = 5 est: 3.3333333333333335 %\n",
      "Erreur pour k = 6 est: 4.0 %\n",
      "Erreur pour k = 7 est: 3.3333333333333335 %\n",
      "Erreur pour k = 8 est: 3.3333333333333335 %\n",
      "Erreur pour k = 9 est: 4.0 %\n"
     ]
    }
   ],
   "source": [
    "# 5\n",
    "from collections import defaultdict\n",
    "def PPV(X,Y,k=1):\n",
    "    loo = LeaveOneOut()\n",
    "    res=[]\n",
    "    \n",
    "    for train_index, test_index in loo.split(X):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = Y[train_index], Y[test_index]\n",
    "        \n",
    "        distances = euclidean_distances(X_train,X_test).flatten()\n",
    "        indexs = np.argsort(distances)\n",
    "        ppv = y_train[indexs][0:k]\n",
    "\n",
    "        d = defaultdict(int)\n",
    "        for e in ppv:\n",
    "            d[e] += 1\n",
    "            \n",
    "        if list(d.values())[0]==1 or not all(x==list(d.values())[0] for x in list(d.values())):\n",
    "            res.append(max(d,key=d.__getitem__))\n",
    "            \n",
    "        else: # cas: [1,1,2,2] || [1,2,1,1,2,2]\n",
    "            moyenne_distances=defaultdict()\n",
    "            for el in sorted(d):\n",
    "                index_classes=[i for i, e in enumerate(ppv) if e == el]\n",
    "                moyenne_distances[el] =sum(np.array(distances[indexs])[index_classes ])\n",
    "            res.append(min(moyenne_distances, key=(lambda q: moyenne_distances[q])))\n",
    "        \n",
    "        erreur = len([res[i] for i in range(0, len(res)) if res[i] != Y[i]])/len(res)\n",
    "    return res,erreur\n",
    "\n",
    "for i in range(2,10):\n",
    "    y_pred,erreur = PPV(X,Y,k=i)\n",
    "    print(\"Erreur pour k =\",i,\"est:\",erreur*100,\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifieur Bayesien Naïf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '1', '1', '2', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '2', '1', '1', '1', '1', '1', '1', '2', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '2', '2', '2', '2', '2', '2', '1', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '1', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2']\n"
     ]
    }
   ],
   "source": [
    "# 1\n",
    "def CBN(X,Y):\n",
    "    loo = LeaveOneOut()\n",
    "    res = []\n",
    "    for train_index, test_index in loo.split(X):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = Y[train_index], Y[test_index]\n",
    "        \n",
    "        # calcul de p_x_wk pour chaque variable \n",
    "        CBN = dict()\n",
    "        \n",
    "        # pour chaque variable\n",
    "        for nb_features in range(X.shape[1]):\n",
    "            p_variables = dict()\n",
    "            \n",
    "            # pour chaque classe\n",
    "            for i in np.unique(Y):\n",
    "                index_of_class_i = np.argwhere(Y==i).flatten()\n",
    "                features_of_class_i = X[index_of_class_i,nb_features]\n",
    "                p_variable_in_class = dict()\n",
    "                for j in np.unique(features_of_class_i):\n",
    "                    p_variable_in_class[j] = np.size(features_of_class_i[features_of_class_i==j])/np.size(features_of_class_i)\n",
    "                p_variables[\"Class \"+str(i)] = p_variable_in_class\n",
    "            CBN[\"X\"+str(nb_features)] = p_variables\n",
    "        \n",
    "        \n",
    "        # les probabilités pour chaque classe existant\n",
    "        p_class=dict()\n",
    "        for i in np.unique(Y):\n",
    "            p_class['Class '+str(i)]= np.size(Y[Y==i])/np.size(Y)\n",
    "\n",
    "        # prediction\n",
    "        for c in p_class:\n",
    "            for v,w in zip(X_test.flatten(),[i for i in CBN]):\n",
    "                try:\n",
    "                    exist = CBN[w][c][v]\n",
    "                except:\n",
    "                    exist = 0\n",
    "                p_class[c] *= exist\n",
    "\n",
    "        res.append(max(p_class,key=p_class.__getitem__)[-1])\n",
    "    return res\n",
    "print(CBN(X,Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erreur: 3.3333333333333335 %\n"
     ]
    }
   ],
   "source": [
    "# 2\n",
    "def CBN(X,Y):\n",
    "    loo = LeaveOneOut()\n",
    "    res = []\n",
    "    for train_index, test_index in loo.split(X):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = Y[train_index], Y[test_index]\n",
    "        \n",
    "        # calcul de p_x_wk pour chaque variable \n",
    "        CBN = dict()\n",
    "        \n",
    "        # pour chaque variable\n",
    "        for nb_features in range(X.shape[1]):\n",
    "            p_variables = dict()\n",
    "            \n",
    "            # pour chaque classe\n",
    "            for i in np.unique(Y):\n",
    "                index_of_class_i = np.argwhere(Y==i).flatten()\n",
    "                features_of_class_i = X[index_of_class_i,nb_features]\n",
    "                p_variable_in_class = dict()\n",
    "                for j in np.unique(features_of_class_i):\n",
    "                    p_variable_in_class[j] = np.size(features_of_class_i[features_of_class_i==j])/np.size(features_of_class_i)\n",
    "                p_variables[\"Class \"+str(i)] = p_variable_in_class\n",
    "            CBN[\"X\"+str(nb_features)] = p_variables\n",
    "        \n",
    "        \n",
    "        # les probabilités pour chaque classe existant\n",
    "        p_class=dict()\n",
    "        for i in np.unique(Y):\n",
    "            p_class['Class '+str(i)]= np.size(Y[Y==i])/np.size(Y)\n",
    "\n",
    "        # prediction\n",
    "        for c in p_class:\n",
    "            for v,w in zip(X_test.flatten(),[i for i in CBN]):\n",
    "                try:\n",
    "                    exist = CBN[w][c][v]\n",
    "                except:\n",
    "                    exist = 0\n",
    "                p_class[c] *= exist\n",
    "\n",
    "        res.append(max(p_class,key=p_class.__getitem__)[-1])\n",
    "    erreur = len([i for i in range(0, len(res)) if int(res[i]) != Y[i]])/len(res)\n",
    "    return res,erreur\n",
    "\n",
    "y_pred,erreur = CBN(X,Y)\n",
    "print(\"Erreur:\",erreur*100,\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erreur= 4.666666666666667 %\n"
     ]
    }
   ],
   "source": [
    "# 3\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "loo = LeaveOneOut()\n",
    "res=[]\n",
    "\n",
    "for train_index, test_index in loo.split(X):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = Y[train_index], Y[test_index]\n",
    "    clf = GaussianNB()\n",
    "    clf.fit(X_train, y_train)\n",
    "    res.append(clf.predict(X_test).flatten()[0])\n",
    "erreur = len([i for i in range(0, len(res)) if int(res[i]) != Y[i]])/len(res)\n",
    "\n",
    "print(\"Erreur=\",erreur*100,\"%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
